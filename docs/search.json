[
  {
    "objectID": "project.html",
    "href": "project.html",
    "title": "Üniversite Sayısının İstihdam ve İşsizliğe Etkisi",
    "section": "",
    "text": "Proje sayfamıza hoş geldiniz!\nTuncay Özkardeş ve İzzet Can Özbaş olarak yürüttüğümüz bu projede; yıllara göre istihdam sayısı, yıllara göre mezun verebilecek üniversite sayısı son olarak ise yıllara ve eğitim durumuna göre işsizlik oranı istatistikleri ile bazı bulgular yakalamaya çalışacağız.\nGüncellemeler için takipte kalın."
  },
  {
    "objectID": "project.html#veri-kaynağı",
    "href": "project.html#veri-kaynağı",
    "title": "Üniversite Sayısının İstihdam ve İşsizliğe Etkisi",
    "section": "2.1 Veri Kaynağı",
    "text": "2.1 Veri Kaynağı\nhttps://data.tuik.gov.tr/ adresinden işsizlik ve istihdam verilerini topladık.\nhttps://istatistik.yok.gov.tr/ adresinden üniversiteler hakkında genel bilgiler veri tabanına ulaştık."
  },
  {
    "objectID": "project.html#veri-hakkında-genel-bilgiler",
    "href": "project.html#veri-hakkında-genel-bilgiler",
    "title": "Üniversite Sayısının İstihdam ve İşsizliğe Etkisi",
    "section": "2.2 Veri Hakkında Genel Bilgiler",
    "text": "2.2 Veri Hakkında Genel Bilgiler\nİstihdam ve işsizlik ile ilgili veriler 1988’den beri tutulmaktadır. Üniversiteler hakkında genel bilgiler ise tüm açılmış üniversiteleri kapsamaktadır.\nBu projede kullandığımız ham veriler farklı kaynaklardan geldiği ve doğrudan analiz edilebilir formatta olmadığı için kapsamlı bir ön işleme (preprocessing) süreci uygulanmıştır."
  },
  {
    "objectID": "project.html#bu-verileri-neden-seçtik",
    "href": "project.html#bu-verileri-neden-seçtik",
    "title": "Üniversite Sayısının İstihdam ve İşsizliğe Etkisi",
    "section": "2.3 Bu Verileri Neden Seçtik?",
    "text": "2.3 Bu Verileri Neden Seçtik?\nUzun yıllardır gelişmekte olan ve işsizlikle boğuşan ülkemizde açılan üniversite sayısının istihdam oranına bir katkı sağlayıp sağlamadığına bakacağız.\nİstihdam artış oranı ile işsizlik artış oranları arasındaki ilişkileri gözlemlemeye çalışacağız.\nÜniversite mezunu işsizlerin üniversite sayısı ile bağlantısını göstermeye çalışacağız."
  },
  {
    "objectID": "project.html#ön-analiz",
    "href": "project.html#ön-analiz",
    "title": "Üniversite Sayısının İstihdam ve İşsizliğe Etkisi",
    "section": "2.4 Ön Analiz",
    "text": "2.4 Ön Analiz\n\n2.4.1 İstihdam Verisi\nHam veri TÜİK sitesinden yıllık bazda alınmıştır. 1988-1999, 2000-2013 ve 2014-2024 yıllarını kapsayan 3 farklı veri tabanı excel üzerinden direkt birleştirilmiştir.\nVeride “Yıl” ve “İstihdam Sayısı” değişkenleri bulunmaktadır.\nİstihdam sayıları bin kişi cinsinden verildiği için, 1000 ile çarpılarak (excel üzerinden yapıldı) gerçek kişi sayılarına dönüştürülmüştür.\nSütun isimleri Türkçe karakter içermeyecek şekilde ayarlanmıştır.\n\n\n2.4.2 İşsizlik Verisi\nHam veri TÜİK’ten eğitim durumuna ve yıllara göre işsizlik oranları şeklinde alınmıştır.\nİşsizlik verisinde yaş gruplarına göre olan kayıtlar çıkarılmış, sadece eğitim durumuna göre kayıtlar alınmıştır. Sütun adları standartlaştırılmıştır (örneğin: “İlkokul”, “Ortaokul”, “Üniversite”).\nYıl bilgisi eksik veya farklı kodlanmış olan satırlar temizlenmiştir. (excel üzerinden yapıldı)\nData long forma çevrilmiştir. Detaylı form açıklamasına 2.5 başlığında görebilirsiniz.\n\n\n2.4.3 Üniversiteler Verisi\nHam veri YÖK Atlas veri tabanından alınmıştır.\nVerideki ilk satır başlık bilgisi olduğu için çıkarılmıştır.\nKuruluş yılı bilgisi Kuruluş Yılı kolonundan alınmıştır.\nÜniversitelerin mezun vermeye 4 yıl sonra başladığı varsayılarak, her üniversite için “Mezun Verebileceği Yıl” = “Kuruluş Yılı” + 4 şeklinde hesap yapılmıştır.\n1988 yılı öncesinde mezun verebilecek üniversiteler ayrıca hesaplanarak 1988 yılına başlangıç değeri olarak eklenmiştir.\n1988–2024 yılları arasındaki yıllık ve kümülatif mezun verebilecek üniversite sayıları hesaplanmıştır."
  },
  {
    "objectID": "project.html#veriyi-kullanıma-hazır-hale-getirme",
    "href": "project.html#veriyi-kullanıma-hazır-hale-getirme",
    "title": "Üniversite Sayısının İstihdam ve İşsizliğe Etkisi",
    "section": "2.5 Veriyi Kullanıma Hazır Hale Getirme",
    "text": "2.5 Veriyi Kullanıma Hazır Hale Getirme\nÖncelikle aşağıdaki gibi paketleri yüklemeli ve ilgili kütüphaneleri çağırmalıyız.\nProjemizin içine açtığımız Project_Data isimli klasörün içine excel dosyalarımızı atıp bunları R üzerinden görelim.\n\nistihdam &lt;- istihdam &lt;- read_excel(\"Project_Data/Istihdam.xlsx\")\nissizlik &lt;- read_excel(\"Project_Data/IssizlikOranlari.xlsx\")\nuniversiteler_raw &lt;- read_excel(\"Project_Data/Universiteler.xlsx\",skip = 1)\n\ndatatable(istihdam)\n\n\n\n\ndatatable(issizlik)\n\n\n\n\ndatatable(universiteler_raw)\n\n\n\n\n\nÜniversite verisinde ilk satırı (başlığı) atalım. 2. Sütun ismini Kurulus_Yili olarak değiştirelim. Daha sonra gg.aa.yy formatındaki tarihin sadece yıl kısmını alalım. Son olarak mezun verebileceği yılları yan sütuna kaydedelim. Ayrıca en üstteki satır başlık olduğu için onu da yukarıda skip=1 diyerek atladık.\n\nuniversiteler &lt;- universiteler_raw %&gt;%\n  select(Kurulus_Yili) %&gt;%\n  mutate(\n    Kurulus_Yili = as.numeric(substr(Kurulus_Yili, 7, 10)),  # Sadece yıl kısmını çekiyoruz (2010 gibi)\n    Mezun_Verebilecegi_Yil = Kurulus_Yili + 4\n  )\n\ndatatable(universiteler)\n\n\n\n\n\n1988’den önce mezun verebilecek durumdaki üniversiteleri bulmalıyız. Çünkü, 1988 den ihtibaren kümülatif ilerleyeceğiz. Amacımız bir yıldaki mezun verebilecek üniversite sayısını görebilmek.\n\n# 1. 1988'den önce mezun verebilecek üniversite sayısını hesaplayalım\nilk_toplam &lt;- universiteler %&gt;%\n  filter(Mezun_Verebilecegi_Yil &lt; 1988) %&gt;%\n  summarise(toplam = n()) %&gt;%\n  pull(toplam)\n\nprint(ilk_toplam)\n\n[1] 27\n\n\n1988’den sonra yıllık olarak mezun verebilecek üniversite sayısını hesaplayalım.\n\nuni_sayisi &lt;- universiteler %&gt;%\n  filter(Mezun_Verebilecegi_Yil &gt;= 1988, Mezun_Verebilecegi_Yil &lt;= 2024) %&gt;%\n  group_by(Mezun_Verebilecegi_Yil) %&gt;%\n  summarise(mezun_verebilecek_uni_sayisi = n()) %&gt;%\n  rename(Yil = Mezun_Verebilecegi_Yil) %&gt;%\n  arrange(Yil)\n\n#1988 yili yoksa manuel olarak eklemeliyiz (grafiklerimiz bu tarihten ihtibaren baslayacak)\nif (!1988 %in% uni_sayisi$Yil) {\n  uni_sayisi &lt;- bind_rows(\n    tibble(Yil = 1988, mezun_verebilecek_uni_sayisi = 0), # 1988'de hiç yeni mezun yoksa bile sıfır olarak ekle\n    uni_sayisi\n  ) %&gt;%\n    arrange(Yil)\n}\n\n#1988 yılındaki üniversite sayısına 1988 ve öncesindeki mezun verebilecek üniversite sayısını eklemeliyiz.\n\nuni_sayisi &lt;- uni_sayisi %&gt;%\n  mutate(mezun_verebilecek_uni_sayisi = ifelse(Yil == 1988, mezun_verebilecek_uni_sayisi + ilk_toplam, mezun_verebilecek_uni_sayisi))\n\n#Kümülatif olarak artacağı için cusum kullanacağız.\nuni_sayisi &lt;- uni_sayisi %&gt;%\n  mutate(kumulatif_mezun_verebilecek_uni_sayisi = cumsum(mezun_verebilecek_uni_sayisi))\n\ndatatable(uni_sayisi)\n\n\n\n\n\nUfak bir grafik ile mezun verebilecek üniversite sayılarını görelim.\n\np &lt;- ggplot(uni_sayisi, aes(x = Yil, y = kumulatif_mezun_verebilecek_uni_sayisi)) +\n  geom_line(color = \"blue\", linewidth = 1.2) +  # Çizgi mavi\n  geom_point(color = \"blue\", size = 2) +  # Noktalar mavi\n  scale_x_continuous(breaks = seq(1988, 2024, by = 5)) +  # 5'er yıllık aralıklar x ekseninde\n  scale_y_continuous(breaks = seq(0, 220, by = 20)) +    # y ekseninde 20'şer aralık\n  labs(\n    title = \"Yillara Gore Kumulatif Mezun Verebilecek Universite Sayisi\",\n    x = \"Yil\",\n    y = \"Kumulatif Mezun Verebilecek Universite Sayisi\"\n  ) +\n  theme_minimal() +\n  theme(\n    panel.grid.major.x = element_line(color = \"grey70\", linetype = \"dashed\"),  # X ekseni gridini kesik yap\n    panel.grid.major.y = element_line(color = \"grey70\", linetype = \"dashed\"),  # Y ekseni gridini kesik yap\n    panel.grid.minor = element_blank(),  # Minor gridleri kaldır\n    axis.text = element_text(size = 10),\n    axis.title = element_text(size = 12),\n    plot.title = element_text(size = 14, hjust = 0.5)  # Başlığı ortala\n  )\n\nprint(p)\n\n\n\n\n\n\n\n\nGörüldüğü üzere 88 yılına kadar mezun verebilen 27 üniversite bulunuyor. 2009 ve sonrası ise fazla bir artış söz konusu.\nŞimdi de yıllara göre istihdam sayısında bir göz atalım.\n\nggplot(istihdam, aes(x = Yil, y = Istihdam_Sayisi)) +\n  geom_line(color = \"blue\", linewidth = 1.2) +\n  geom_point(color = \"blue\", size = 2) +\n  scale_x_continuous(breaks = seq(1988, 2024, by = 5)) +\n  scale_y_continuous(breaks = seq(0, 40000000, by = 5000000),\n                     labels = label_comma()) +  # burada değişiklik yaptık!\n  labs(\n    title = \"Yillara Gore Istihdam Sayisi\",\n    x = \"Yil\",\n    y = \"Istihdam_Sayisi\"\n  ) +\n  theme_minimal() +\n  theme(\n    panel.grid.major.x = element_line(color = \"grey70\", linetype = \"dashed\"),\n    panel.grid.major.y = element_line(color = \"grey70\", linetype = \"dashed\"),\n    panel.grid.minor = element_blank(),\n    axis.text = element_text(size = 10),\n    axis.title = element_text(size = 12),\n    plot.title = element_text(size = 14, hjust = 0.5)\n  )\n\n\n\n\n\n\n\n\n2018’den sonraki koronavirüs dönemindeki düşüşü gördünüz mü!\nŞimdi Tidyr kullanarak işsizlik datasını long hale çevirelim ve normal/long hani arasındaki farkları görelim.\n\nissizlik_long &lt;- issizlik %&gt;%\n  pivot_longer(\n    cols = -Yil,\n    names_to = \"Egitim_Durumu\",\n    values_to = \"Issizlik_Orani\"\n  )\ndatatable(issizlik)\n\n\n\n\ndatatable(issizlik_long)\n\n\n\n\n\nLong data üzerinden tüm veriler için rahatça grafik çizebiliriz.\n\nggplot(issizlik_long, aes(x = Yil, y = Issizlik_Orani, color = Egitim_Durumu)) +\n  geom_line(linewidth = 1.2) + \n  geom_point(size = 2) +\n  scale_x_continuous(breaks = seq(1988, 2024, by = 5)) +\n  scale_y_continuous(limits = c(0, 30)) +\n  labs(\n    title = \"Yillara Gore Egitim Durumuna Bagli Issizlik Oranlari\",\n    x = \"Yil\",\n    y = \"Issizlik Orani (%)\",\n    color = \"Egitim Durumu\"  # Legend başlığı\n  ) +\n  theme_minimal() +\n  theme(\n    panel.grid.major.x = element_line(color = \"grey80\", linetype = \"dashed\"),\n    panel.grid.major.y = element_line(color = \"grey80\", linetype = \"dashed\"),\n    panel.grid.minor = element_blank(),\n    legend.position = \"bottom\",  # Legend aşağıda\n    legend.title = element_text(size = 11),\n    legend.text = element_text(size = 10),\n    plot.title = element_text(size = 14, hjust = 0.5)\n  )\n\n\n\n\n\n\n\n\nGöründüğü üzere üniversite okuyanların işsizlik oranı okuma yazma bilmeyenlerin oranına göre daha fazla! Devamına final projede detaylı olarak değineceğiz.\nSon olarak verilerimizi Rdata formatında saklayalım.\n\nsave(istihdam, issizlik, issizlik_long, uni_sayisi, file = \"Project_Data/son_veriler.RData\")\n\nRData dosyalarını buradan indirebilirsiniz"
  },
  {
    "objectID": "project.html#exploratory-data-analysis",
    "href": "project.html#exploratory-data-analysis",
    "title": "Üniversite Sayısının İstihdam ve İşsizliğe Etkisi",
    "section": "3.1 Exploratory Data Analysis",
    "text": "3.1 Exploratory Data Analysis\nxxxxxx"
  },
  {
    "objectID": "project.html#trend-analysis",
    "href": "project.html#trend-analysis",
    "title": "Üniversite Sayısının İstihdam ve İşsizliğe Etkisi",
    "section": "3.2 Trend Analysis",
    "text": "3.2 Trend Analysis\nxxxxxx"
  },
  {
    "objectID": "project.html#model-fitting",
    "href": "project.html#model-fitting",
    "title": "Üniversite Sayısının İstihdam ve İşsizliğe Etkisi",
    "section": "3.3 Model Fitting",
    "text": "3.3 Model Fitting\nxxxxxx"
  },
  {
    "objectID": "project.html#results",
    "href": "project.html#results",
    "title": "Üniversite Sayısının İstihdam ve İşsizliğe Etkisi",
    "section": "3.4 Results",
    "text": "3.4 Results\nxxxxxx"
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "My Blog",
    "section": "",
    "text": "This page is under construction.\n\n\n\n Back to top"
  },
  {
    "objectID": "assignments.html",
    "href": "assignments.html",
    "title": "My Assignments",
    "section": "",
    "text": "On this page, I showcase the assignment I conducted for the Spring 2024-2025 EMU660 Decision Making with Analytics course.\nPlease use left menu to navigate through my assignments.\n\n\n\n Back to top",
    "crumbs": [
      "My Assignments"
    ]
  },
  {
    "objectID": "assignments/assignment-1.html",
    "href": "assignments/assignment-1.html",
    "title": "Assignment 1",
    "section": "",
    "text": "My first assignment has two parts.",
    "crumbs": [
      "Assignment 1"
    ]
  },
  {
    "objectID": "assignments/assignment-1.html#a-summary-of-the-discussion-titled-data-science-and-industrial-engineering",
    "href": "assignments/assignment-1.html#a-summary-of-the-discussion-titled-data-science-and-industrial-engineering",
    "title": "Assignment 1",
    "section": "(a) Summary of the Discussion Titled “Data Science and Industrial Engineering”",
    "text": "(a) Summary of the Discussion Titled “Data Science and Industrial Engineering”\nHello Everyone,\nI would like to share my inferences about the video that includes a detailed discussion about “Data Science and Industrial Engineering” between host: Erdi Dasdemir and Cem Vardar.\nThe talk begins with a discussion on the definition of Industrial Engineering and the potential roles that graduates can take on. It then explores the scope of data science and its relationship with industrial engineering. One of the most crucial connections is the ability of industrial engineers to leverage data science tools to enhance operational research (OR) and use optimization techniques more effectively.\nCem Vardar highlights various job opportunities where industrial engineers can apply data science tools, emphasizing that this field offers broad career prospects and a promising future. He also shares insights on how professionals can integrate data science methodologies into their work to improve decision-making and efficiency. Lastly, the talk provides practical advice on developing essential skills, understanding industry needs, and navigating career paths in both industrial engineering and data science.",
    "crumbs": [
      "Assignment 1"
    ]
  },
  {
    "objectID": "assignments/assignment-1.html#b-exploration-of-statistical-summaries-with-custom-functions-and-iterations-methods",
    "href": "assignments/assignment-1.html#b-exploration-of-statistical-summaries-with-custom-functions-and-iterations-methods",
    "title": "Assignment 1",
    "section": "(b) Exploration of Statistical Summaries with Custom Functions and Iterations Methods",
    "text": "(b) Exploration of Statistical Summaries with Custom Functions and Iterations Methods\n\nFirst we need to write our function\n\nlibrary(dslabs)\n\nWarning: package 'dslabs' was built under R version 4.3.3\n\ndata(mtcars)\n\ncompute_stats &lt;- function(x) {\n  stats &lt;- list(\n    mean = mean(x, na.rm = TRUE),\n    median = median(x, na.rm = TRUE),\n    variance = var(x, na.rm = TRUE),\n    iqr = IQR(x, na.rm = TRUE),\n    min = min(x, na.rm = TRUE),\n    max = max(x, na.rm = TRUE)\n  )\n  return(stats)\n}\n\n\n\nNow we need to plug our coulmn values in to the function\n\nfor (columns in colnames(mtcars)) {\n  cat(\"\\nStatistics for:\", columns, \"\\n\")\n  print(compute_stats(mtcars[[columns]]))\n}\n\n\nStatistics for: mpg \n$mean\n[1] 20.09062\n\n$median\n[1] 19.2\n\n$variance\n[1] 36.3241\n\n$iqr\n[1] 7.375\n\n$min\n[1] 10.4\n\n$max\n[1] 33.9\n\n\nStatistics for: cyl \n$mean\n[1] 6.1875\n\n$median\n[1] 6\n\n$variance\n[1] 3.189516\n\n$iqr\n[1] 4\n\n$min\n[1] 4\n\n$max\n[1] 8\n\n\nStatistics for: disp \n$mean\n[1] 230.7219\n\n$median\n[1] 196.3\n\n$variance\n[1] 15360.8\n\n$iqr\n[1] 205.175\n\n$min\n[1] 71.1\n\n$max\n[1] 472\n\n\nStatistics for: hp \n$mean\n[1] 146.6875\n\n$median\n[1] 123\n\n$variance\n[1] 4700.867\n\n$iqr\n[1] 83.5\n\n$min\n[1] 52\n\n$max\n[1] 335\n\n\nStatistics for: drat \n$mean\n[1] 3.596563\n\n$median\n[1] 3.695\n\n$variance\n[1] 0.2858814\n\n$iqr\n[1] 0.84\n\n$min\n[1] 2.76\n\n$max\n[1] 4.93\n\n\nStatistics for: wt \n$mean\n[1] 3.21725\n\n$median\n[1] 3.325\n\n$variance\n[1] 0.957379\n\n$iqr\n[1] 1.02875\n\n$min\n[1] 1.513\n\n$max\n[1] 5.424\n\n\nStatistics for: qsec \n$mean\n[1] 17.84875\n\n$median\n[1] 17.71\n\n$variance\n[1] 3.193166\n\n$iqr\n[1] 2.0075\n\n$min\n[1] 14.5\n\n$max\n[1] 22.9\n\n\nStatistics for: vs \n$mean\n[1] 0.4375\n\n$median\n[1] 0\n\n$variance\n[1] 0.2540323\n\n$iqr\n[1] 1\n\n$min\n[1] 0\n\n$max\n[1] 1\n\n\nStatistics for: am \n$mean\n[1] 0.40625\n\n$median\n[1] 0\n\n$variance\n[1] 0.2489919\n\n$iqr\n[1] 1\n\n$min\n[1] 0\n\n$max\n[1] 1\n\n\nStatistics for: gear \n$mean\n[1] 3.6875\n\n$median\n[1] 4\n\n$variance\n[1] 0.5443548\n\n$iqr\n[1] 1\n\n$min\n[1] 3\n\n$max\n[1] 5\n\n\nStatistics for: carb \n$mean\n[1] 2.8125\n\n$median\n[1] 2\n\n$variance\n[1] 2.608871\n\n$iqr\n[1] 2\n\n$min\n[1] 1\n\n$max\n[1] 8\n\nlibrary(dplyr)\n\nWarning: package 'dplyr' was built under R version 4.3.3\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\n\n\nWe can make this loop with using sapply and apply\n\nstats_sapply &lt;- sapply(mtcars, compute_stats)\nprint(stats_sapply)\n\n         mpg      cyl      disp     hp       drat      wt       qsec    \nmean     20.09062 6.1875   230.7219 146.6875 3.596563  3.21725  17.84875\nmedian   19.2     6        196.3    123      3.695     3.325    17.71   \nvariance 36.3241  3.189516 15360.8  4700.867 0.2858814 0.957379 3.193166\niqr      7.375    4        205.175  83.5     0.84      1.02875  2.0075  \nmin      10.4     4        71.1     52       2.76      1.513    14.5    \nmax      33.9     8        472      335      4.93      5.424    22.9    \n         vs        am        gear      carb    \nmean     0.4375    0.40625   3.6875    2.8125  \nmedian   0         0         4         2       \nvariance 0.2540323 0.2489919 0.5443548 2.608871\niqr      1         1         1         2       \nmin      0         0         3         1       \nmax      1         1         5         8       \n\nstats_apply &lt;- apply(mtcars, 2, compute_stats)\nprint(stats_apply)\n\n$mpg\n$mpg$mean\n[1] 20.09062\n\n$mpg$median\n[1] 19.2\n\n$mpg$variance\n[1] 36.3241\n\n$mpg$iqr\n[1] 7.375\n\n$mpg$min\n[1] 10.4\n\n$mpg$max\n[1] 33.9\n\n\n$cyl\n$cyl$mean\n[1] 6.1875\n\n$cyl$median\n[1] 6\n\n$cyl$variance\n[1] 3.189516\n\n$cyl$iqr\n[1] 4\n\n$cyl$min\n[1] 4\n\n$cyl$max\n[1] 8\n\n\n$disp\n$disp$mean\n[1] 230.7219\n\n$disp$median\n[1] 196.3\n\n$disp$variance\n[1] 15360.8\n\n$disp$iqr\n[1] 205.175\n\n$disp$min\n[1] 71.1\n\n$disp$max\n[1] 472\n\n\n$hp\n$hp$mean\n[1] 146.6875\n\n$hp$median\n[1] 123\n\n$hp$variance\n[1] 4700.867\n\n$hp$iqr\n[1] 83.5\n\n$hp$min\n[1] 52\n\n$hp$max\n[1] 335\n\n\n$drat\n$drat$mean\n[1] 3.596563\n\n$drat$median\n[1] 3.695\n\n$drat$variance\n[1] 0.2858814\n\n$drat$iqr\n[1] 0.84\n\n$drat$min\n[1] 2.76\n\n$drat$max\n[1] 4.93\n\n\n$wt\n$wt$mean\n[1] 3.21725\n\n$wt$median\n[1] 3.325\n\n$wt$variance\n[1] 0.957379\n\n$wt$iqr\n[1] 1.02875\n\n$wt$min\n[1] 1.513\n\n$wt$max\n[1] 5.424\n\n\n$qsec\n$qsec$mean\n[1] 17.84875\n\n$qsec$median\n[1] 17.71\n\n$qsec$variance\n[1] 3.193166\n\n$qsec$iqr\n[1] 2.0075\n\n$qsec$min\n[1] 14.5\n\n$qsec$max\n[1] 22.9\n\n\n$vs\n$vs$mean\n[1] 0.4375\n\n$vs$median\n[1] 0\n\n$vs$variance\n[1] 0.2540323\n\n$vs$iqr\n[1] 1\n\n$vs$min\n[1] 0\n\n$vs$max\n[1] 1\n\n\n$am\n$am$mean\n[1] 0.40625\n\n$am$median\n[1] 0\n\n$am$variance\n[1] 0.2489919\n\n$am$iqr\n[1] 1\n\n$am$min\n[1] 0\n\n$am$max\n[1] 1\n\n\n$gear\n$gear$mean\n[1] 3.6875\n\n$gear$median\n[1] 4\n\n$gear$variance\n[1] 0.5443548\n\n$gear$iqr\n[1] 1\n\n$gear$min\n[1] 3\n\n$gear$max\n[1] 5\n\n\n$carb\n$carb$mean\n[1] 2.8125\n\n$carb$median\n[1] 2\n\n$carb$variance\n[1] 2.608871\n\n$carb$iqr\n[1] 2\n\n$carb$min\n[1] 1\n\n$carb$max\n[1] 8",
    "crumbs": [
      "Assignment 1"
    ]
  },
  {
    "objectID": "assignments/assignment-1.html#c-na-example",
    "href": "assignments/assignment-1.html#c-na-example",
    "title": "Assignment 1",
    "section": "(c) “NA” example",
    "text": "(c) “NA” example\n\nLets print the example first\n\nlibrary(dslabs)\ndata(\"na_example\")\nprint(na_example)\n\n   [1]  2  1  3  2  1  3  1  4  3  2  2 NA  2  2  1  4 NA  1  1  2  1  2  2  1\n  [25]  2  5 NA  2  2  3  1  2  4  1  1  1  4  5  2  3  4  1  2  4  1  1  2  1\n  [49]  5 NA NA NA  1  1  5  1  3  1 NA  4  4  7  3  2 NA NA  1 NA  4  1  2  2\n  [73]  3  2  1  2  2  4  3  4  2  3  1  3  2  1  1  1  3  1 NA  3  1  2  2  1\n  [97]  2  2  1  1  4  1  1  2  3  3  2  2  3  3  3  4  1  1  1  2 NA  4  3  4\n [121]  3  1  2  1 NA NA NA NA  1  5  1  2  1  3  5  3  2  2 NA NA NA NA  3  5\n [145]  3  1  1  4  2  4  3  3 NA  2  3  2  6 NA  1  1  2  2  1  3  1  1  5 NA\n [169] NA  2  4 NA  2  5  1  4  3  3 NA  4  3  1  4  1  1  3  1  1 NA NA  3  5\n [193]  2  2  2  3  1  2  2  3  2  1 NA  2 NA  1 NA NA  2  1  1 NA  3 NA  1  2\n [217]  2  1  3  2  2  1  1  2  3  1  1  1  4  3  4  2  2  1  4  1 NA  5  1  4\n [241] NA  3 NA NA  1  1  5  2  3  3  2  4 NA  3  2  5 NA  2  3  4  6  2  2  2\n [265] NA  2 NA  2 NA  3  3  2  2  4  3  1  4  2 NA  2  4 NA  6  2  3  1 NA  2\n [289]  2 NA  1  1  3  2  3  3  1 NA  1  4  2  1  1  3  2  1  2  3  1 NA  2  3\n [313]  3  2  1  2  3  5  5  1  2  3  3  1 NA NA  1  2  4 NA  2  1  1  1  3  2\n [337]  1  1  3  4 NA  1  2  1  1  3  3 NA  1  1  3  5  3  2  3  4  1  4  3  1\n [361] NA  2  1  2  2  1  2  2  6  1  2  4  5 NA  3  4  2  1  1  4  2  1  1  1\n [385]  1  2  1  4  4  1  3 NA  3  3 NA  2 NA  1  2  1  1  4  2  1  4  4 NA  1\n [409]  2 NA  3  2  2  2  1  4  3  6  1  2  3  1  3  2  2  2  1  1  3  2  1  1\n [433]  1  3  2  2 NA  4  4  4  1  1 NA  4  3 NA  1  3  1  3  2  4  2  2  2  3\n [457]  2  1  4  3 NA  1  4  3  1  3  2 NA  3 NA  1  3  1  4  1  1  1  2  4  3\n [481]  1  2  2  2  3  2  3  1  1 NA  3  2  1  1  2 NA  2  2  2  3  3  1  1  2\n [505] NA  1  2  1  1  3  3  1  3  1  1  1  1  1  2  5  1  1  2  2  1  1 NA  1\n [529]  4  1  2  4  1  3  2 NA  1  1 NA  2  1  1  4  2  3  3  1  5  3  1  1  2\n [553] NA  1  1  3  1  3  2  4 NA  2  3  2  1  2  1  1  1  2  2  3  1  5  2 NA\n [577]  2 NA  3  2  2  2  1  5  3  2  3  1 NA  3  1  2  2  2  1  2  2  4 NA  6\n [601]  1  2 NA  1  1  2  2  3 NA  3  2  3  3  4  2 NA  2 NA  4 NA  1  1  2  2\n [625]  3  1  1  1  3 NA  2  5 NA  7  1 NA  4  3  3  1 NA  1  1  1  1  3  2  4\n [649]  2  2  3 NA NA  1  4  3  2  2  2  3  2  4  2  2  4 NA NA NA  6  3  3  1\n [673]  4  4  2  1 NA  1  6 NA  3  3  2  1  1  6 NA  1  5  1 NA  2  6  2 NA  4\n [697]  1  3  1  2 NA  1  1  3  1  2  4  2  1  3  2  4  3  2  2  1  1  5  6  4\n [721]  2  2  2  2  4 NA  1  2  2  2  2  4  5 NA NA NA  4  3  3  3  2  4  2  4\n [745] NA NA NA NA  2  1 NA  2  4  3  2 NA  2  3  1  3  4 NA  1  2  1  2 NA  3\n [769]  1  2  1  2  1  2  1  2  2  2  2  1  1  3  3  1  3  4  3 NA NA  4  2  3\n [793]  2  1  3  2  4  2  2  3  1  2  4  3  3  4 NA  1  4  2  1  1  1  3  1  5\n [817]  2  2  4  2 NA  1  3  1  2 NA  1  2  1  2  1 NA  1  3  2  3  2 NA  2  1\n [841]  4  2 NA NA NA  2  4  2 NA NA  3  1 NA  5  5  2  2  2 NA  2  1  3  1  3\n [865]  2  4  2  4 NA  4  1  2  3  2  3  3  2  3  2  2  2  1  3  2  4  2 NA  3\n [889]  3  2  2 NA NA  3  2  1  2  4  1  1  1  1  4  3  2 NA  3  2 NA  1 NA  3\n [913]  2  1  1  1  2 NA  2  2  3  3  2 NA NA  4  5  2  2  2  1  2  3  1  3  3\n [937]  4  3 NA  1  1  1 NA  4  3  5  1  1  2 NA  2  2  2  2  5  2  2  3  1  2\n [961]  3 NA  1  2 NA NA  2 NA  3  1  1  2  5  3  5  1  1  4 NA  2  1  3  1  1\n [985]  2  4  3  3  3 NA  1  1  2  2  1  1  2  2 NA  2\n\n\n\n\nTotal Count and Indexes of NA’s\n\n# Number of NA's\nnum_na &lt;- sum(is.na(na_example))\ncat(\"Total NA values:\", num_na, \"\\n\")\n\nTotal NA values: 145 \n\n# Indexes\nna_positions &lt;- which(is.na(na_example))\ncat(\"NA positions:\", na_positions, \"\\n\")\n\nNA positions: 12 17 27 50 51 52 59 65 66 68 91 117 125 126 127 128 139 140 141 142 153 158 168 169 172 179 189 190 203 205 207 208 212 214 237 241 243 244 253 257 265 267 269 279 282 287 290 298 310 325 326 330 341 348 361 374 392 395 397 407 410 437 443 446 461 468 470 490 496 505 527 536 539 553 561 576 578 589 599 603 609 616 618 620 630 633 636 641 652 653 666 667 668 677 680 687 691 695 701 726 734 735 736 745 746 747 748 751 756 762 767 788 789 807 821 826 832 838 843 844 845 849 850 853 859 869 887 892 893 906 909 911 918 924 925 939 943 950 962 965 966 968 979 990 999 \n\n\n\n\nComputation Mean and Std. Deviation by Ignoring NA’s\n\nmean_value &lt;- mean(na_example, na.rm = TRUE)\nsd_value &lt;- sd(na_example, na.rm = TRUE)\n\ncat(\"Mean (ignoring NA):\", mean_value, \"\\n\")\n\nMean (ignoring NA): 2.301754 \n\ncat(\"Standard Deviation (ignoring NA):\", sd_value, \"\\n\")\n\nStandard Deviation (ignoring NA): 1.22338 \n\n\n\n\nHandling Missing Values\n\n# Version 1: Replace NA values with the median of non-missing values\nmedian_value &lt;- median(na_example, na.rm = TRUE)\nna_example_v1 &lt;- na_example\nna_example_v1[is.na(na_example_v1)] &lt;- median_value\n\n# Version 2: Replace NA values with a randomly selected non-missing value\nnon_na_values &lt;- na_example[!is.na(na_example)]\nna_example_v2 &lt;- na_example\nna_example_v2[is.na(na_example_v2)] &lt;- sample(non_na_values, sum(is.na(na_example_v2)), replace = TRUE)\n\n# Display modified datasets\ncat(\"\\nDataset with NA replaced by median:\\n\")\n\n\nDataset with NA replaced by median:\n\nprint(na_example_v1)\n\n   [1] 2 1 3 2 1 3 1 4 3 2 2 2 2 2 1 4 2 1 1 2 1 2 2 1 2 5 2 2 2 3 1 2 4 1 1 1 4\n  [38] 5 2 3 4 1 2 4 1 1 2 1 5 2 2 2 1 1 5 1 3 1 2 4 4 7 3 2 2 2 1 2 4 1 2 2 3 2\n  [75] 1 2 2 4 3 4 2 3 1 3 2 1 1 1 3 1 2 3 1 2 2 1 2 2 1 1 4 1 1 2 3 3 2 2 3 3 3\n [112] 4 1 1 1 2 2 4 3 4 3 1 2 1 2 2 2 2 1 5 1 2 1 3 5 3 2 2 2 2 2 2 3 5 3 1 1 4\n [149] 2 4 3 3 2 2 3 2 6 2 1 1 2 2 1 3 1 1 5 2 2 2 4 2 2 5 1 4 3 3 2 4 3 1 4 1 1\n [186] 3 1 1 2 2 3 5 2 2 2 3 1 2 2 3 2 1 2 2 2 1 2 2 2 1 1 2 3 2 1 2 2 1 3 2 2 1\n [223] 1 2 3 1 1 1 4 3 4 2 2 1 4 1 2 5 1 4 2 3 2 2 1 1 5 2 3 3 2 4 2 3 2 5 2 2 3\n [260] 4 6 2 2 2 2 2 2 2 2 3 3 2 2 4 3 1 4 2 2 2 4 2 6 2 3 1 2 2 2 2 1 1 3 2 3 3\n [297] 1 2 1 4 2 1 1 3 2 1 2 3 1 2 2 3 3 2 1 2 3 5 5 1 2 3 3 1 2 2 1 2 4 2 2 1 1\n [334] 1 3 2 1 1 3 4 2 1 2 1 1 3 3 2 1 1 3 5 3 2 3 4 1 4 3 1 2 2 1 2 2 1 2 2 6 1\n [371] 2 4 5 2 3 4 2 1 1 4 2 1 1 1 1 2 1 4 4 1 3 2 3 3 2 2 2 1 2 1 1 4 2 1 4 4 2\n [408] 1 2 2 3 2 2 2 1 4 3 6 1 2 3 1 3 2 2 2 1 1 3 2 1 1 1 3 2 2 2 4 4 4 1 1 2 4\n [445] 3 2 1 3 1 3 2 4 2 2 2 3 2 1 4 3 2 1 4 3 1 3 2 2 3 2 1 3 1 4 1 1 1 2 4 3 1\n [482] 2 2 2 3 2 3 1 1 2 3 2 1 1 2 2 2 2 2 3 3 1 1 2 2 1 2 1 1 3 3 1 3 1 1 1 1 1\n [519] 2 5 1 1 2 2 1 1 2 1 4 1 2 4 1 3 2 2 1 1 2 2 1 1 4 2 3 3 1 5 3 1 1 2 2 1 1\n [556] 3 1 3 2 4 2 2 3 2 1 2 1 1 1 2 2 3 1 5 2 2 2 2 3 2 2 2 1 5 3 2 3 1 2 3 1 2\n [593] 2 2 1 2 2 4 2 6 1 2 2 1 1 2 2 3 2 3 2 3 3 4 2 2 2 2 4 2 1 1 2 2 3 1 1 1 3\n [630] 2 2 5 2 7 1 2 4 3 3 1 2 1 1 1 1 3 2 4 2 2 3 2 2 1 4 3 2 2 2 3 2 4 2 2 4 2\n [667] 2 2 6 3 3 1 4 4 2 1 2 1 6 2 3 3 2 1 1 6 2 1 5 1 2 2 6 2 2 4 1 3 1 2 2 1 1\n [704] 3 1 2 4 2 1 3 2 4 3 2 2 1 1 5 6 4 2 2 2 2 4 2 1 2 2 2 2 4 5 2 2 2 4 3 3 3\n [741] 2 4 2 4 2 2 2 2 2 1 2 2 4 3 2 2 2 3 1 3 4 2 1 2 1 2 2 3 1 2 1 2 1 2 1 2 2\n [778] 2 2 1 1 3 3 1 3 4 3 2 2 4 2 3 2 1 3 2 4 2 2 3 1 2 4 3 3 4 2 1 4 2 1 1 1 3\n [815] 1 5 2 2 4 2 2 1 3 1 2 2 1 2 1 2 1 2 1 3 2 3 2 2 2 1 4 2 2 2 2 2 4 2 2 2 3\n [852] 1 2 5 5 2 2 2 2 2 1 3 1 3 2 4 2 4 2 4 1 2 3 2 3 3 2 3 2 2 2 1 3 2 4 2 2 3\n [889] 3 2 2 2 2 3 2 1 2 4 1 1 1 1 4 3 2 2 3 2 2 1 2 3 2 1 1 1 2 2 2 2 3 3 2 2 2\n [926] 4 5 2 2 2 1 2 3 1 3 3 4 3 2 1 1 1 2 4 3 5 1 1 2 2 2 2 2 2 5 2 2 3 1 2 3 2\n [963] 1 2 2 2 2 2 3 1 1 2 5 3 5 1 1 4 2 2 1 3 1 1 2 4 3 3 3 2 1 1 2 2 1 1 2 2 2\n[1000] 2\n\ncat(\"\\nDataset with NA replaced by random non-missing value:\\n\")\n\n\nDataset with NA replaced by random non-missing value:\n\nprint(na_example_v2)\n\n   [1] 2 1 3 2 1 3 1 4 3 2 2 1 2 2 1 4 2 1 1 2 1 2 2 1 2 5 4 2 2 3 1 2 4 1 1 1 4\n  [38] 5 2 3 4 1 2 4 1 1 2 1 5 1 1 3 1 1 5 1 3 1 1 4 4 7 3 2 4 2 1 4 4 1 2 2 3 2\n  [75] 1 2 2 4 3 4 2 3 1 3 2 1 1 1 3 1 3 3 1 2 2 1 2 2 1 1 4 1 1 2 3 3 2 2 3 3 3\n [112] 4 1 1 1 2 1 4 3 4 3 1 2 1 2 2 1 3 1 5 1 2 1 3 5 3 2 2 2 2 2 3 3 5 3 1 1 4\n [149] 2 4 3 3 1 2 3 2 6 6 1 1 2 2 1 3 1 1 5 2 2 2 4 1 2 5 1 4 3 3 2 4 3 1 4 1 1\n [186] 3 1 1 2 4 3 5 2 2 2 3 1 2 2 3 2 1 1 2 1 1 2 1 2 1 1 2 3 2 1 2 2 1 3 2 2 1\n [223] 1 2 3 1 1 1 4 3 4 2 2 1 4 1 1 5 1 4 2 3 2 3 1 1 5 2 3 3 2 4 1 3 2 5 2 2 3\n [260] 4 6 2 2 2 2 2 2 2 5 3 3 2 2 4 3 1 4 2 1 2 4 2 6 2 3 1 2 2 2 1 1 1 3 2 3 3\n [297] 1 2 1 4 2 1 1 3 2 1 2 3 1 1 2 3 3 2 1 2 3 5 5 1 2 3 3 1 1 1 1 2 4 1 2 1 1\n [334] 1 3 2 1 1 3 4 3 1 2 1 1 3 3 3 1 1 3 5 3 2 3 4 1 4 3 1 1 2 1 2 2 1 2 2 6 1\n [371] 2 4 5 2 3 4 2 1 1 4 2 1 1 1 1 2 1 4 4 1 3 2 3 3 1 2 5 1 2 1 1 4 2 1 4 4 2\n [408] 1 2 1 3 2 2 2 1 4 3 6 1 2 3 1 3 2 2 2 1 1 3 2 1 1 1 3 2 2 2 4 4 4 1 1 1 4\n [445] 3 2 1 3 1 3 2 4 2 2 2 3 2 1 4 3 2 1 4 3 1 3 2 2 3 5 1 3 1 4 1 1 1 2 4 3 1\n [482] 2 2 2 3 2 3 1 1 1 3 2 1 1 2 5 2 2 2 3 3 1 1 2 1 1 2 1 1 3 3 1 3 1 1 1 1 1\n [519] 2 5 1 1 2 2 1 1 2 1 4 1 2 4 1 3 2 1 1 1 3 2 1 1 4 2 3 3 1 5 3 1 1 2 3 1 1\n [556] 3 1 3 2 4 3 2 3 2 1 2 1 1 1 2 2 3 1 5 2 1 2 1 3 2 2 2 1 5 3 2 3 1 1 3 1 2\n [593] 2 2 1 2 2 4 2 6 1 2 1 1 1 2 2 3 2 3 2 3 3 4 2 3 2 3 4 1 1 1 2 2 3 1 1 1 3\n [630] 1 2 5 2 7 1 2 4 3 3 1 2 1 1 1 1 3 2 4 2 2 3 1 4 1 4 3 2 2 2 3 2 4 2 2 4 1\n [667] 2 3 6 3 3 1 4 4 2 1 4 1 6 2 3 3 2 1 1 6 2 1 5 1 1 2 6 2 2 4 1 3 1 2 2 1 1\n [704] 3 1 2 4 2 1 3 2 4 3 2 2 1 1 5 6 4 2 2 2 2 4 2 1 2 2 2 2 4 5 1 3 1 4 3 3 3\n [741] 2 4 2 4 3 6 2 1 2 1 3 2 4 3 2 2 2 3 1 3 4 2 1 2 1 2 2 3 1 2 1 2 1 2 1 2 2\n [778] 2 2 1 1 3 3 1 3 4 3 3 3 4 2 3 2 1 3 2 4 2 2 3 1 2 4 3 3 4 2 1 4 2 1 1 1 3\n [815] 1 5 2 2 4 2 3 1 3 1 2 1 1 2 1 2 1 4 1 3 2 3 2 2 2 1 4 2 5 1 1 2 4 2 1 2 3\n [852] 1 3 5 5 2 2 2 5 2 1 3 1 3 2 4 2 4 1 4 1 2 3 2 3 3 2 3 2 2 2 1 3 2 4 2 4 3\n [889] 3 2 2 5 1 3 2 1 2 4 1 1 1 1 4 3 2 5 3 2 2 1 2 3 2 1 1 1 2 2 2 2 3 3 2 2 3\n [926] 4 5 2 2 2 1 2 3 1 3 3 4 3 1 1 1 1 2 4 3 5 1 1 2 2 2 2 2 2 5 2 2 3 1 2 3 3\n [963] 1 2 2 1 2 1 3 1 1 2 5 3 5 1 1 4 3 2 1 3 1 1 2 4 3 3 3 2 1 1 2 2 1 1 2 2 2\n[1000] 2",
    "crumbs": [
      "Assignment 1"
    ]
  },
  {
    "objectID": "about.html#employements",
    "href": "about.html#employements",
    "title": "About Me",
    "section": "Employements",
    "text": "Employements\n\nAselsan ILS Planning and Analysis Engineer 10.2024 - Ongoing\nOtokar Purchasing Candidate Engineer 01.2024 - 10.2024"
  },
  {
    "objectID": "about.html#internships",
    "href": "about.html#internships",
    "title": "About Me",
    "section": "Internships",
    "text": "Internships\n\nMKE A.Ş., Supply Chain Intern, 2023\nTürk Traktör, Bill of Material Intern, 2023"
  },
  {
    "objectID": "assignments/assignment-2.html",
    "href": "assignments/assignment-2.html",
    "title": "Assignment 2",
    "section": "",
    "text": "Assignment 2\n\n1 + 1\n\n[1] 2\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Assignment 2"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to My Analytics Lab",
    "section": "",
    "text": "Hello!! My name is Tuncay Özkardeş\nThis is my personal webpage.\nPlease stay tuned to follow my works on data analytics, blog posts, and more.\n\n\n\n Back to top"
  },
  {
    "objectID": "presentation.html",
    "href": "presentation.html",
    "title": "Presentation",
    "section": "",
    "text": "You can download our presentation in the link below:\nDownload–Presentation\n\n\n\n Back to top"
  }
]